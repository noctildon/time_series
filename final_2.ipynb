{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0adabef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "830469f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4730e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Synthetic Dataset ---\n",
    "class SeqLabelingDataset(Dataset):\n",
    "    def __init__(self, n_samples=100, min_len=5, max_len=15, dyn_feat_dim=4, static_feat_dim=2, num_classes=3):\n",
    "        self.samples = []\n",
    "        for _ in range(n_samples):\n",
    "            seq_len = random.randint(min_len, max_len)\n",
    "            dyn_feat = torch.randn(seq_len, dyn_feat_dim)\n",
    "            static_feat = torch.randn(static_feat_dim)\n",
    "            labels = torch.randint(0, num_classes, (seq_len,))\n",
    "            self.samples.append((dyn_feat, static_feat, labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "# --- 2. Collate function ---\n",
    "def collate_fn(batch):\n",
    "    dyn_seqs, stat_feats, label_seqs = zip(*batch)\n",
    "    lengths = torch.tensor([len(seq) for seq in dyn_seqs])\n",
    "\n",
    "    padded_dyn = pad_sequence(dyn_seqs, batch_first=True)  # [B, T, F]\n",
    "    padded_labels = pad_sequence(label_seqs, batch_first=True, padding_value=-100)  # [B, T]\n",
    "    static_feats = torch.stack(stat_feats)  # [B, S]\n",
    "\n",
    "    return padded_dyn, static_feats, lengths, padded_labels\n",
    "\n",
    "# --- 3. LSTM Model ---\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, dyn_feat_dim, static_feat_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(dyn_feat_dim, hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim + static_feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_dyn, x_static, lengths):\n",
    "        packed_input = pack_padded_sequence(x_dyn, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)  # [B, T, H]\n",
    "\n",
    "        # Expand static features to [B, T, S]\n",
    "        B, T, _ = lstm_out.shape\n",
    "        x_static_exp = x_static.unsqueeze(1).expand(B, T, -1)\n",
    "\n",
    "        combined = torch.cat([lstm_out, x_static_exp], dim=-1)  # [B, T, H+S]\n",
    "        logits = self.classifier(combined)  # [B, T, C]\n",
    "        return logits\n",
    "\n",
    "# --- 4. Accuracy with masking ---\n",
    "def masked_accuracy(logits, labels, pad_val=-100):\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    mask = labels != pad_val\n",
    "    correct = (preds == labels) & mask\n",
    "    acc = correct.sum().float() / mask.sum()\n",
    "    return acc.item()\n",
    "\n",
    "def compute_class_weights(dataset, num_classes, pad_val=-100):\n",
    "    all_labels = []\n",
    "    for _, _, label_seq in dataset:\n",
    "        all_labels.extend(label_seq.tolist())\n",
    "    filtered_labels = [lb for lb in all_labels if lb != pad_val]\n",
    "    label_counts = Counter(filtered_labels)\n",
    "\n",
    "    # Inverse frequency\n",
    "    counts = torch.tensor([label_counts.get(i, 1) for i in range(num_classes)], dtype=torch.float)\n",
    "    weights = 1.0 / counts\n",
    "    weights = weights / weights.sum()  # normalize\n",
    "    return weights\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, pad_val=-100):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_acc = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_dyn, x_static, lengths, labels in dataloader:\n",
    "            x_dyn = x_dyn.to(device)\n",
    "            x_static = x_static.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(x_dyn, x_static, lengths)\n",
    "            acc = masked_accuracy(logits, labels, pad_val)\n",
    "            total_acc += acc\n",
    "            batches += 1\n",
    "\n",
    "            ###\n",
    "            # preds = logits.argmax(dim=-1)\n",
    "            # mask = labels != pad_val\n",
    "            # all_preds.extend(preds[mask].cpu().numpy())\n",
    "            # all_labels.extend(labels[mask].cpu().numpy())\n",
    "\n",
    "    return total_acc / batches\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    # cm = confusion_matrix(all_labels, all_preds)\n",
    "    # report = classification_report(all_labels, all_preds, digits=4)\n",
    "    # return accuracy_score(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614fd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_feat_dim = 4\n",
    "static_feat_dim = 2\n",
    "hidden_dim = 32\n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "\n",
    "dataset = SeqLabelingDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa6a73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 4]), torch.Size([2]), torch.Size([14]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dataset.samples[3]\n",
    "d[0].shape, d[1].shape, d[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5222c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.1020 | Train Accuracy: 0.3229 | Test Acc: 0.3416\n",
      "\n",
      "\n",
      "Epoch 2 | Train Loss: 1.0996 | Train Accuracy: 0.3290 | Test Acc: 0.3518\n",
      "\n",
      "\n",
      "Epoch 3 | Train Loss: 1.0963 | Train Accuracy: 0.3595 | Test Acc: 0.3509\n",
      "\n",
      "\n",
      "Epoch 4 | Train Loss: 1.0994 | Train Accuracy: 0.3412 | Test Acc: 0.3361\n",
      "\n",
      "\n",
      "Epoch 5 | Train Loss: 1.0980 | Train Accuracy: 0.3458 | Test Acc: 0.3795\n",
      "\n",
      "\n",
      "Epoch 6 | Train Loss: 1.0955 | Train Accuracy: 0.3727 | Test Acc: 0.3548\n",
      "\n",
      "\n",
      "Epoch 7 | Train Loss: 1.0950 | Train Accuracy: 0.3601 | Test Acc: 0.3803\n",
      "\n",
      "\n",
      "Epoch 8 | Train Loss: 1.0958 | Train Accuracy: 0.3490 | Test Acc: 0.3712\n",
      "\n",
      "\n",
      "Epoch 9 | Train Loss: 1.0928 | Train Accuracy: 0.3875 | Test Acc: 0.3686\n",
      "\n",
      "\n",
      "Epoch 10 | Train Loss: 1.0942 | Train Accuracy: 0.3700 | Test Acc: 0.3717\n",
      "\n",
      "\n",
      "Epoch 11 | Train Loss: 1.0946 | Train Accuracy: 0.3681 | Test Acc: 0.3820\n",
      "\n",
      "\n",
      "Epoch 12 | Train Loss: 1.0943 | Train Accuracy: 0.3697 | Test Acc: 0.3943\n",
      "\n",
      "\n",
      "Epoch 13 | Train Loss: 1.0906 | Train Accuracy: 0.4033 | Test Acc: 0.3968\n",
      "\n",
      "\n",
      "Epoch 14 | Train Loss: 1.0932 | Train Accuracy: 0.3854 | Test Acc: 0.4060\n",
      "\n",
      "\n",
      "Epoch 15 | Train Loss: 1.0903 | Train Accuracy: 0.4052 | Test Acc: 0.4074\n",
      "\n",
      "\n",
      "Epoch 16 | Train Loss: 1.0895 | Train Accuracy: 0.4068 | Test Acc: 0.4050\n",
      "\n",
      "\n",
      "Epoch 17 | Train Loss: 1.0862 | Train Accuracy: 0.4131 | Test Acc: 0.4040\n",
      "\n",
      "\n",
      "Epoch 18 | Train Loss: 1.0851 | Train Accuracy: 0.4156 | Test Acc: 0.4065\n",
      "\n",
      "\n",
      "Epoch 19 | Train Loss: 1.0837 | Train Accuracy: 0.4178 | Test Acc: 0.4152\n",
      "\n",
      "\n",
      "Epoch 20 | Train Loss: 1.0811 | Train Accuracy: 0.4179 | Test Acc: 0.4192\n",
      "\n",
      "\n",
      "Epoch 21 | Train Loss: 1.0807 | Train Accuracy: 0.4129 | Test Acc: 0.4213\n",
      "\n",
      "\n",
      "Epoch 22 | Train Loss: 1.0790 | Train Accuracy: 0.4315 | Test Acc: 0.4097\n",
      "\n",
      "\n",
      "Epoch 23 | Train Loss: 1.0745 | Train Accuracy: 0.4200 | Test Acc: 0.4218\n",
      "\n",
      "\n",
      "Epoch 24 | Train Loss: 1.0779 | Train Accuracy: 0.4057 | Test Acc: 0.4112\n",
      "\n",
      "\n",
      "Epoch 25 | Train Loss: 1.0767 | Train Accuracy: 0.4187 | Test Acc: 0.4257\n",
      "\n",
      "\n",
      "Epoch 26 | Train Loss: 1.0749 | Train Accuracy: 0.4113 | Test Acc: 0.4130\n",
      "\n",
      "\n",
      "Epoch 27 | Train Loss: 1.0746 | Train Accuracy: 0.4190 | Test Acc: 0.4088\n",
      "\n",
      "\n",
      "Epoch 28 | Train Loss: 1.0786 | Train Accuracy: 0.4020 | Test Acc: 0.4147\n",
      "\n",
      "\n",
      "Epoch 29 | Train Loss: 1.0688 | Train Accuracy: 0.4247 | Test Acc: 0.4036\n",
      "\n",
      "\n",
      "Epoch 30 | Train Loss: 1.0693 | Train Accuracy: 0.4132 | Test Acc: 0.4294\n",
      "\n",
      "\n",
      "Epoch 31 | Train Loss: 1.0782 | Train Accuracy: 0.4108 | Test Acc: 0.4130\n",
      "\n",
      "\n",
      "Epoch 32 | Train Loss: 1.0747 | Train Accuracy: 0.4087 | Test Acc: 0.4205\n",
      "\n",
      "\n",
      "Epoch 33 | Train Loss: 1.0622 | Train Accuracy: 0.4211 | Test Acc: 0.4106\n",
      "\n",
      "\n",
      "Epoch 34 | Train Loss: 1.0658 | Train Accuracy: 0.4046 | Test Acc: 0.4168\n",
      "\n",
      "\n",
      "Epoch 35 | Train Loss: 1.0666 | Train Accuracy: 0.3987 | Test Acc: 0.4237\n",
      "\n",
      "\n",
      "Epoch 36 | Train Loss: 1.0670 | Train Accuracy: 0.4040 | Test Acc: 0.4205\n",
      "\n",
      "\n",
      "Epoch 37 | Train Loss: 1.0655 | Train Accuracy: 0.4138 | Test Acc: 0.4167\n",
      "\n",
      "\n",
      "Epoch 38 | Train Loss: 1.0636 | Train Accuracy: 0.4199 | Test Acc: 0.4287\n",
      "\n",
      "\n",
      "Epoch 39 | Train Loss: 1.0594 | Train Accuracy: 0.4303 | Test Acc: 0.4179\n",
      "\n",
      "\n",
      "Epoch 40 | Train Loss: 1.0566 | Train Accuracy: 0.4298 | Test Acc: 0.4143\n",
      "\n",
      "\n",
      "Epoch 41 | Train Loss: 1.0548 | Train Accuracy: 0.4373 | Test Acc: 0.4273\n",
      "\n",
      "\n",
      "Epoch 42 | Train Loss: 1.0565 | Train Accuracy: 0.4253 | Test Acc: 0.4460\n",
      "\n",
      "\n",
      "Epoch 43 | Train Loss: 1.0539 | Train Accuracy: 0.4482 | Test Acc: 0.4469\n",
      "\n",
      "\n",
      "Epoch 44 | Train Loss: 1.0465 | Train Accuracy: 0.4507 | Test Acc: 0.4462\n",
      "\n",
      "\n",
      "Epoch 45 | Train Loss: 1.0510 | Train Accuracy: 0.4335 | Test Acc: 0.4352\n",
      "\n",
      "\n",
      "Epoch 46 | Train Loss: 1.0472 | Train Accuracy: 0.4367 | Test Acc: 0.4339\n",
      "\n",
      "\n",
      "Epoch 47 | Train Loss: 1.0458 | Train Accuracy: 0.4555 | Test Acc: 0.4487\n",
      "\n",
      "\n",
      "Epoch 48 | Train Loss: 1.0469 | Train Accuracy: 0.4483 | Test Acc: 0.4579\n",
      "\n",
      "\n",
      "Epoch 49 | Train Loss: 1.0503 | Train Accuracy: 0.4465 | Test Acc: 0.4551\n",
      "\n",
      "\n",
      "Epoch 50 | Train Loss: 1.0434 | Train Accuracy: 0.4600 | Test Acc: 0.4562\n",
      "\n",
      "\n",
      "Epoch 51 | Train Loss: 1.0415 | Train Accuracy: 0.4663 | Test Acc: 0.4612\n",
      "\n",
      "\n",
      "Epoch 52 | Train Loss: 1.0396 | Train Accuracy: 0.4673 | Test Acc: 0.4563\n",
      "\n",
      "\n",
      "Epoch 53 | Train Loss: 1.0419 | Train Accuracy: 0.4560 | Test Acc: 0.4814\n",
      "\n",
      "\n",
      "Epoch 54 | Train Loss: 1.0382 | Train Accuracy: 0.4544 | Test Acc: 0.4702\n",
      "\n",
      "\n",
      "Epoch 55 | Train Loss: 1.0345 | Train Accuracy: 0.4686 | Test Acc: 0.4586\n",
      "\n",
      "\n",
      "Epoch 56 | Train Loss: 1.0283 | Train Accuracy: 0.4657 | Test Acc: 0.4613\n",
      "\n",
      "\n",
      "Epoch 57 | Train Loss: 1.0273 | Train Accuracy: 0.4703 | Test Acc: 0.4683\n",
      "\n",
      "\n",
      "Epoch 58 | Train Loss: 1.0273 | Train Accuracy: 0.4744 | Test Acc: 0.4722\n",
      "\n",
      "\n",
      "Epoch 59 | Train Loss: 1.0194 | Train Accuracy: 0.4845 | Test Acc: 0.4719\n",
      "\n",
      "\n",
      "Epoch 60 | Train Loss: 1.0201 | Train Accuracy: 0.4859 | Test Acc: 0.4829\n",
      "\n",
      "\n",
      "Epoch 61 | Train Loss: 1.0280 | Train Accuracy: 0.4672 | Test Acc: 0.4899\n",
      "\n",
      "\n",
      "Epoch 62 | Train Loss: 1.0131 | Train Accuracy: 0.4889 | Test Acc: 0.4802\n",
      "\n",
      "\n",
      "Epoch 63 | Train Loss: 1.0106 | Train Accuracy: 0.4925 | Test Acc: 0.4846\n",
      "\n",
      "\n",
      "Epoch 64 | Train Loss: 1.0148 | Train Accuracy: 0.4802 | Test Acc: 0.4961\n",
      "\n",
      "\n",
      "Epoch 65 | Train Loss: 1.0059 | Train Accuracy: 0.5020 | Test Acc: 0.4891\n",
      "\n",
      "\n",
      "Epoch 66 | Train Loss: 1.0029 | Train Accuracy: 0.4901 | Test Acc: 0.4807\n",
      "\n",
      "\n",
      "Epoch 67 | Train Loss: 0.9952 | Train Accuracy: 0.4932 | Test Acc: 0.4886\n",
      "\n",
      "\n",
      "Epoch 68 | Train Loss: 1.0043 | Train Accuracy: 0.4979 | Test Acc: 0.4977\n",
      "\n",
      "\n",
      "Epoch 69 | Train Loss: 1.0019 | Train Accuracy: 0.4874 | Test Acc: 0.5077\n",
      "\n",
      "\n",
      "Epoch 70 | Train Loss: 0.9954 | Train Accuracy: 0.5024 | Test Acc: 0.5050\n",
      "\n",
      "\n",
      "Epoch 71 | Train Loss: 0.9853 | Train Accuracy: 0.5130 | Test Acc: 0.4923\n",
      "\n",
      "\n",
      "Epoch 72 | Train Loss: 0.9892 | Train Accuracy: 0.4889 | Test Acc: 0.5065\n",
      "\n",
      "\n",
      "Epoch 73 | Train Loss: 0.9954 | Train Accuracy: 0.4875 | Test Acc: 0.5128\n",
      "\n",
      "\n",
      "Epoch 74 | Train Loss: 0.9936 | Train Accuracy: 0.5044 | Test Acc: 0.5143\n",
      "\n",
      "\n",
      "Epoch 75 | Train Loss: 0.9802 | Train Accuracy: 0.5121 | Test Acc: 0.5156\n",
      "\n",
      "\n",
      "Epoch 76 | Train Loss: 0.9789 | Train Accuracy: 0.5125 | Test Acc: 0.5044\n",
      "\n",
      "\n",
      "Epoch 77 | Train Loss: 0.9705 | Train Accuracy: 0.5185 | Test Acc: 0.5299\n",
      "\n",
      "\n",
      "Epoch 78 | Train Loss: 0.9862 | Train Accuracy: 0.4949 | Test Acc: 0.5034\n",
      "\n",
      "\n",
      "Epoch 79 | Train Loss: 0.9734 | Train Accuracy: 0.5110 | Test Acc: 0.5148\n",
      "\n",
      "\n",
      "Epoch 80 | Train Loss: 0.9719 | Train Accuracy: 0.5199 | Test Acc: 0.5118\n",
      "\n",
      "\n",
      "Epoch 81 | Train Loss: 0.9694 | Train Accuracy: 0.5090 | Test Acc: 0.5122\n",
      "\n",
      "\n",
      "Epoch 82 | Train Loss: 0.9538 | Train Accuracy: 0.5448 | Test Acc: 0.5208\n",
      "\n",
      "\n",
      "Epoch 83 | Train Loss: 0.9608 | Train Accuracy: 0.5263 | Test Acc: 0.5181\n",
      "\n",
      "\n",
      "Epoch 84 | Train Loss: 0.9627 | Train Accuracy: 0.5196 | Test Acc: 0.5270\n",
      "\n",
      "\n",
      "Epoch 85 | Train Loss: 0.9588 | Train Accuracy: 0.5118 | Test Acc: 0.5465\n",
      "\n",
      "\n",
      "Epoch 86 | Train Loss: 0.9567 | Train Accuracy: 0.5283 | Test Acc: 0.5210\n",
      "\n",
      "\n",
      "Epoch 87 | Train Loss: 0.9595 | Train Accuracy: 0.5304 | Test Acc: 0.5397\n",
      "\n",
      "\n",
      "Epoch 88 | Train Loss: 0.9576 | Train Accuracy: 0.5335 | Test Acc: 0.5248\n",
      "\n",
      "\n",
      "Epoch 89 | Train Loss: 0.9538 | Train Accuracy: 0.5242 | Test Acc: 0.5308\n",
      "\n",
      "\n",
      "Epoch 90 | Train Loss: 0.9568 | Train Accuracy: 0.5376 | Test Acc: 0.5456\n",
      "\n",
      "\n",
      "Epoch 91 | Train Loss: 0.9412 | Train Accuracy: 0.5352 | Test Acc: 0.5202\n",
      "\n",
      "\n",
      "Epoch 92 | Train Loss: 0.9397 | Train Accuracy: 0.5421 | Test Acc: 0.5565\n",
      "\n",
      "\n",
      "Epoch 93 | Train Loss: 0.9378 | Train Accuracy: 0.5577 | Test Acc: 0.5511\n",
      "\n",
      "\n",
      "Epoch 94 | Train Loss: 0.9329 | Train Accuracy: 0.5505 | Test Acc: 0.5493\n",
      "\n",
      "\n",
      "Epoch 95 | Train Loss: 0.9298 | Train Accuracy: 0.5643 | Test Acc: 0.5613\n",
      "\n",
      "\n",
      "Epoch 96 | Train Loss: 0.9346 | Train Accuracy: 0.5388 | Test Acc: 0.5593\n",
      "\n",
      "\n",
      "Epoch 97 | Train Loss: 0.9386 | Train Accuracy: 0.5494 | Test Acc: 0.5645\n",
      "\n",
      "\n",
      "Epoch 98 | Train Loss: 0.9271 | Train Accuracy: 0.5546 | Test Acc: 0.5515\n",
      "\n",
      "\n",
      "Epoch 99 | Train Loss: 0.9330 | Train Accuracy: 0.5375 | Test Acc: 0.5504\n",
      "\n",
      "\n",
      "Epoch 100 | Train Loss: 0.9241 | Train Accuracy: 0.5559 | Test Acc: 0.5599\n",
      "\n",
      "\n",
      "Epoch 101 | Train Loss: 0.9142 | Train Accuracy: 0.5446 | Test Acc: 0.5662\n",
      "\n",
      "\n",
      "Epoch 102 | Train Loss: 0.9137 | Train Accuracy: 0.5676 | Test Acc: 0.5741\n",
      "\n",
      "\n",
      "Epoch 103 | Train Loss: 0.9196 | Train Accuracy: 0.5651 | Test Acc: 0.5625\n",
      "\n",
      "\n",
      "Epoch 104 | Train Loss: 0.9020 | Train Accuracy: 0.5819 | Test Acc: 0.5709\n",
      "\n",
      "\n",
      "Epoch 105 | Train Loss: 0.9137 | Train Accuracy: 0.5651 | Test Acc: 0.5631\n",
      "\n",
      "\n",
      "Epoch 106 | Train Loss: 0.9049 | Train Accuracy: 0.5721 | Test Acc: 0.5657\n",
      "\n",
      "\n",
      "Epoch 107 | Train Loss: 0.9038 | Train Accuracy: 0.5713 | Test Acc: 0.5623\n",
      "\n",
      "\n",
      "Epoch 108 | Train Loss: 0.9037 | Train Accuracy: 0.5680 | Test Acc: 0.5676\n",
      "\n",
      "\n",
      "Epoch 109 | Train Loss: 0.9087 | Train Accuracy: 0.5647 | Test Acc: 0.5703\n",
      "\n",
      "\n",
      "Epoch 110 | Train Loss: 0.9000 | Train Accuracy: 0.5734 | Test Acc: 0.5628\n",
      "\n",
      "\n",
      "Epoch 111 | Train Loss: 0.9061 | Train Accuracy: 0.5659 | Test Acc: 0.5611\n",
      "\n",
      "\n",
      "Epoch 112 | Train Loss: 0.8852 | Train Accuracy: 0.5694 | Test Acc: 0.5786\n",
      "\n",
      "\n",
      "Epoch 113 | Train Loss: 0.8932 | Train Accuracy: 0.5607 | Test Acc: 0.5761\n",
      "\n",
      "\n",
      "Epoch 114 | Train Loss: 0.8800 | Train Accuracy: 0.5885 | Test Acc: 0.5928\n",
      "\n",
      "\n",
      "Epoch 115 | Train Loss: 0.9072 | Train Accuracy: 0.5642 | Test Acc: 0.5868\n",
      "\n",
      "\n",
      "Epoch 116 | Train Loss: 0.8883 | Train Accuracy: 0.5922 | Test Acc: 0.5881\n",
      "\n",
      "\n",
      "Epoch 117 | Train Loss: 0.8808 | Train Accuracy: 0.5920 | Test Acc: 0.5846\n",
      "\n",
      "\n",
      "Epoch 118 | Train Loss: 0.8844 | Train Accuracy: 0.5816 | Test Acc: 0.5918\n",
      "\n",
      "\n",
      "Epoch 119 | Train Loss: 0.8773 | Train Accuracy: 0.5961 | Test Acc: 0.5953\n",
      "\n",
      "\n",
      "Epoch 120 | Train Loss: 0.8684 | Train Accuracy: 0.6012 | Test Acc: 0.5931\n",
      "\n",
      "\n",
      "Epoch 121 | Train Loss: 0.8703 | Train Accuracy: 0.5815 | Test Acc: 0.5809\n",
      "\n",
      "\n",
      "Epoch 122 | Train Loss: 0.8727 | Train Accuracy: 0.5886 | Test Acc: 0.5946\n",
      "\n",
      "\n",
      "Epoch 123 | Train Loss: 0.8557 | Train Accuracy: 0.6066 | Test Acc: 0.5992\n",
      "\n",
      "\n",
      "Epoch 124 | Train Loss: 0.8714 | Train Accuracy: 0.5869 | Test Acc: 0.5968\n",
      "\n",
      "\n",
      "Epoch 125 | Train Loss: 0.8505 | Train Accuracy: 0.6116 | Test Acc: 0.5970\n",
      "\n",
      "\n",
      "Epoch 126 | Train Loss: 0.8704 | Train Accuracy: 0.6046 | Test Acc: 0.6175\n",
      "\n",
      "\n",
      "Epoch 127 | Train Loss: 0.8646 | Train Accuracy: 0.6036 | Test Acc: 0.6191\n",
      "\n",
      "\n",
      "Epoch 128 | Train Loss: 0.8477 | Train Accuracy: 0.6160 | Test Acc: 0.6185\n",
      "\n",
      "\n",
      "Epoch 129 | Train Loss: 0.8563 | Train Accuracy: 0.6037 | Test Acc: 0.6209\n",
      "\n",
      "\n",
      "Epoch 130 | Train Loss: 0.8566 | Train Accuracy: 0.6171 | Test Acc: 0.6227\n",
      "\n",
      "\n",
      "Epoch 131 | Train Loss: 0.8580 | Train Accuracy: 0.6114 | Test Acc: 0.6158\n",
      "\n",
      "\n",
      "Epoch 132 | Train Loss: 0.8438 | Train Accuracy: 0.6134 | Test Acc: 0.6094\n",
      "\n",
      "\n",
      "Epoch 133 | Train Loss: 0.8396 | Train Accuracy: 0.6148 | Test Acc: 0.6220\n",
      "\n",
      "\n",
      "Epoch 134 | Train Loss: 0.8390 | Train Accuracy: 0.6188 | Test Acc: 0.6142\n",
      "\n",
      "\n",
      "Epoch 135 | Train Loss: 0.8320 | Train Accuracy: 0.6273 | Test Acc: 0.6196\n",
      "\n",
      "\n",
      "Epoch 136 | Train Loss: 0.8505 | Train Accuracy: 0.6167 | Test Acc: 0.6359\n",
      "\n",
      "\n",
      "Epoch 137 | Train Loss: 0.8306 | Train Accuracy: 0.6429 | Test Acc: 0.6257\n",
      "\n",
      "\n",
      "Epoch 138 | Train Loss: 0.8360 | Train Accuracy: 0.6139 | Test Acc: 0.6326\n",
      "\n",
      "\n",
      "Epoch 139 | Train Loss: 0.8266 | Train Accuracy: 0.6333 | Test Acc: 0.6500\n",
      "\n",
      "\n",
      "Epoch 140 | Train Loss: 0.8262 | Train Accuracy: 0.6350 | Test Acc: 0.6409\n",
      "\n",
      "\n",
      "Epoch 141 | Train Loss: 0.8197 | Train Accuracy: 0.6371 | Test Acc: 0.6273\n",
      "\n",
      "\n",
      "Epoch 142 | Train Loss: 0.8131 | Train Accuracy: 0.6404 | Test Acc: 0.6480\n",
      "\n",
      "\n",
      "Epoch 143 | Train Loss: 0.8145 | Train Accuracy: 0.6494 | Test Acc: 0.6401\n",
      "\n",
      "\n",
      "Epoch 144 | Train Loss: 0.8146 | Train Accuracy: 0.6349 | Test Acc: 0.6345\n",
      "\n",
      "\n",
      "Epoch 145 | Train Loss: 0.8190 | Train Accuracy: 0.6369 | Test Acc: 0.6515\n",
      "\n",
      "\n",
      "Epoch 146 | Train Loss: 0.8049 | Train Accuracy: 0.6510 | Test Acc: 0.6614\n",
      "\n",
      "\n",
      "Epoch 147 | Train Loss: 0.7994 | Train Accuracy: 0.6437 | Test Acc: 0.6365\n",
      "\n",
      "\n",
      "Epoch 148 | Train Loss: 0.8173 | Train Accuracy: 0.6325 | Test Acc: 0.6441\n",
      "\n",
      "\n",
      "Epoch 149 | Train Loss: 0.8176 | Train Accuracy: 0.6460 | Test Acc: 0.6420\n",
      "\n",
      "\n",
      "Epoch 150 | Train Loss: 0.8066 | Train Accuracy: 0.6407 | Test Acc: 0.6524\n",
      "\n",
      "\n",
      "Epoch 151 | Train Loss: 0.8076 | Train Accuracy: 0.6367 | Test Acc: 0.6414\n",
      "\n",
      "\n",
      "Epoch 152 | Train Loss: 0.7861 | Train Accuracy: 0.6611 | Test Acc: 0.6680\n",
      "\n",
      "\n",
      "Epoch 153 | Train Loss: 0.7809 | Train Accuracy: 0.6729 | Test Acc: 0.6682\n",
      "\n",
      "\n",
      "Epoch 154 | Train Loss: 0.7982 | Train Accuracy: 0.6399 | Test Acc: 0.6598\n",
      "\n",
      "\n",
      "Epoch 155 | Train Loss: 0.7851 | Train Accuracy: 0.6600 | Test Acc: 0.6533\n",
      "\n",
      "\n",
      "Epoch 156 | Train Loss: 0.7802 | Train Accuracy: 0.6430 | Test Acc: 0.6564\n",
      "\n",
      "\n",
      "Epoch 157 | Train Loss: 0.7818 | Train Accuracy: 0.6503 | Test Acc: 0.6658\n",
      "\n",
      "\n",
      "Epoch 158 | Train Loss: 0.7862 | Train Accuracy: 0.6534 | Test Acc: 0.6551\n",
      "\n",
      "\n",
      "Epoch 159 | Train Loss: 0.7735 | Train Accuracy: 0.6593 | Test Acc: 0.6406\n",
      "\n",
      "\n",
      "Epoch 160 | Train Loss: 0.7713 | Train Accuracy: 0.6551 | Test Acc: 0.6542\n",
      "\n",
      "\n",
      "Epoch 161 | Train Loss: 0.7772 | Train Accuracy: 0.6484 | Test Acc: 0.6660\n",
      "\n",
      "\n",
      "Epoch 162 | Train Loss: 0.7811 | Train Accuracy: 0.6476 | Test Acc: 0.6526\n",
      "\n",
      "\n",
      "Epoch 163 | Train Loss: 0.7777 | Train Accuracy: 0.6539 | Test Acc: 0.6547\n",
      "\n",
      "\n",
      "Epoch 164 | Train Loss: 0.7788 | Train Accuracy: 0.6481 | Test Acc: 0.6565\n",
      "\n",
      "\n",
      "Epoch 165 | Train Loss: 0.7800 | Train Accuracy: 0.6519 | Test Acc: 0.6652\n",
      "\n",
      "\n",
      "Epoch 166 | Train Loss: 0.7729 | Train Accuracy: 0.6501 | Test Acc: 0.6708\n",
      "\n",
      "\n",
      "Epoch 167 | Train Loss: 0.7670 | Train Accuracy: 0.6558 | Test Acc: 0.6712\n",
      "\n",
      "\n",
      "Epoch 168 | Train Loss: 0.7698 | Train Accuracy: 0.6552 | Test Acc: 0.6816\n",
      "\n",
      "\n",
      "Epoch 169 | Train Loss: 0.7681 | Train Accuracy: 0.6460 | Test Acc: 0.6679\n",
      "\n",
      "\n",
      "Epoch 170 | Train Loss: 0.7723 | Train Accuracy: 0.6579 | Test Acc: 0.6548\n",
      "\n",
      "\n",
      "Epoch 171 | Train Loss: 0.7590 | Train Accuracy: 0.6670 | Test Acc: 0.6724\n",
      "\n",
      "\n",
      "Epoch 172 | Train Loss: 0.7516 | Train Accuracy: 0.6684 | Test Acc: 0.6782\n",
      "\n",
      "\n",
      "Epoch 173 | Train Loss: 0.7510 | Train Accuracy: 0.6619 | Test Acc: 0.6780\n",
      "\n",
      "\n",
      "Epoch 174 | Train Loss: 0.7350 | Train Accuracy: 0.6796 | Test Acc: 0.6632\n",
      "\n",
      "\n",
      "Epoch 175 | Train Loss: 0.7373 | Train Accuracy: 0.6696 | Test Acc: 0.6687\n",
      "\n",
      "\n",
      "Epoch 176 | Train Loss: 0.7472 | Train Accuracy: 0.6763 | Test Acc: 0.6647\n",
      "\n",
      "\n",
      "Epoch 177 | Train Loss: 0.7430 | Train Accuracy: 0.6723 | Test Acc: 0.6832\n",
      "\n",
      "\n",
      "Epoch 178 | Train Loss: 0.7352 | Train Accuracy: 0.6839 | Test Acc: 0.6756\n",
      "\n",
      "\n",
      "Epoch 179 | Train Loss: 0.7312 | Train Accuracy: 0.6856 | Test Acc: 0.6930\n",
      "\n",
      "\n",
      "Epoch 180 | Train Loss: 0.7287 | Train Accuracy: 0.6782 | Test Acc: 0.6691\n",
      "\n",
      "\n",
      "Epoch 181 | Train Loss: 0.7223 | Train Accuracy: 0.6827 | Test Acc: 0.6753\n",
      "\n",
      "\n",
      "Epoch 182 | Train Loss: 0.7192 | Train Accuracy: 0.6738 | Test Acc: 0.6829\n",
      "\n",
      "\n",
      "Epoch 183 | Train Loss: 0.7331 | Train Accuracy: 0.6861 | Test Acc: 0.6720\n",
      "\n",
      "\n",
      "Epoch 184 | Train Loss: 0.7145 | Train Accuracy: 0.6880 | Test Acc: 0.6828\n",
      "\n",
      "\n",
      "Epoch 185 | Train Loss: 0.7245 | Train Accuracy: 0.6862 | Test Acc: 0.6762\n",
      "\n",
      "\n",
      "Epoch 186 | Train Loss: 0.7142 | Train Accuracy: 0.6838 | Test Acc: 0.6893\n",
      "\n",
      "\n",
      "Epoch 187 | Train Loss: 0.7160 | Train Accuracy: 0.6883 | Test Acc: 0.6808\n",
      "\n",
      "\n",
      "Epoch 188 | Train Loss: 0.7063 | Train Accuracy: 0.6888 | Test Acc: 0.6925\n",
      "\n",
      "\n",
      "Epoch 189 | Train Loss: 0.7126 | Train Accuracy: 0.6844 | Test Acc: 0.6879\n",
      "\n",
      "\n",
      "Epoch 190 | Train Loss: 0.6972 | Train Accuracy: 0.6990 | Test Acc: 0.6859\n",
      "\n",
      "\n",
      "Epoch 191 | Train Loss: 0.7223 | Train Accuracy: 0.6855 | Test Acc: 0.6847\n",
      "\n",
      "\n",
      "Epoch 192 | Train Loss: 0.7051 | Train Accuracy: 0.6836 | Test Acc: 0.6981\n",
      "\n",
      "\n",
      "Epoch 193 | Train Loss: 0.7062 | Train Accuracy: 0.6896 | Test Acc: 0.7008\n",
      "\n",
      "\n",
      "Epoch 194 | Train Loss: 0.7010 | Train Accuracy: 0.6844 | Test Acc: 0.6789\n",
      "\n",
      "\n",
      "Epoch 195 | Train Loss: 0.6997 | Train Accuracy: 0.6922 | Test Acc: 0.7046\n",
      "\n",
      "\n",
      "Epoch 196 | Train Loss: 0.6968 | Train Accuracy: 0.6895 | Test Acc: 0.7048\n",
      "\n",
      "\n",
      "Epoch 197 | Train Loss: 0.6984 | Train Accuracy: 0.7082 | Test Acc: 0.6942\n",
      "\n",
      "\n",
      "Epoch 198 | Train Loss: 0.6939 | Train Accuracy: 0.6992 | Test Acc: 0.6853\n",
      "\n",
      "\n",
      "Epoch 199 | Train Loss: 0.6865 | Train Accuracy: 0.6972 | Test Acc: 0.6903\n",
      "\n",
      "\n",
      "Epoch 200 | Train Loss: 0.6783 | Train Accuracy: 0.7012 | Test Acc: 0.6807\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Training setup ---\n",
    "class_weights = compute_class_weights(dataset, num_classes).to(device)\n",
    "model = LSTMTagger(dyn_feat_dim, static_feat_dim, hidden_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100, weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- 6. Training loop ---\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    for x_dyn, x_static, lengths, labels in dataloader:\n",
    "        x_dyn = x_dyn.to(device)\n",
    "        x_static = x_static.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(x_dyn, x_static, lengths)\n",
    "        loss = criterion(logits.view(-1, num_classes), labels.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = masked_accuracy(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        batches += 1\n",
    "\n",
    "    test_acc = evaluate(model, dataloader)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {total_loss/batches:.4f} | Train Accuracy: {total_acc/batches:.4f} | Test Acc: {test_acc:.4f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85998148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
